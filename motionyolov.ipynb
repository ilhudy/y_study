{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "thresh = 25     # 프레임 간 차이 이미지를 이진화할 때 사용할 임계값.\n",
    "max_diff = 5    # 모션 감지를 판단할 때 사용할 최대 차이 픽셀 수.\n",
    "\n",
    "# YOLO 모델 설정\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# COCO 클래스 로드\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "a, b, c = None, None, None\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 720)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 600)\n",
    "if cap.isOpened():\n",
    "    # 첫, 두 프레임을 읽어옴\n",
    "    ret, a = cap.read()\n",
    "    ret, b = cap.read()\n",
    "\n",
    "    while ret:\n",
    "        # 세 번째 프레임을 읽어옴\n",
    "        ret, c = cap.read()\n",
    "        # 현재 프레임을 복사하여 그리기 작업에 사용\n",
    "        draw = c.copy()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # 세 프레임을 그레이스케일로 변환\n",
    "        a_gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        b_gray = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)\n",
    "        c_gray = cv2.cvtColor(c, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 연속된 두 프레임 간의 차이 계산\n",
    "        diff1 = cv2.absdiff(a_gray, b_gray)\n",
    "        diff2 = cv2.absdiff(b_gray, c_gray)\n",
    "\n",
    "        # 차이 이미지에 임계값 적용하여 이진 이미지로 변환\n",
    "        ret, diff1_t = cv2.threshold(diff1, thresh, 255, cv2.THRESH_BINARY)\n",
    "        ret, diff2_t = cv2.threshold(diff2, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # 두 차이 이미지의 비트 AND 연산\n",
    "        diff = cv2.bitwise_and(diff1_t, diff2_t)\n",
    "\n",
    "        # 노이즈 제거를 위해 형태학적 연산 적용\n",
    "        k = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "        diff = cv2.morphologyEx(diff, cv2.MORPH_OPEN, k)\n",
    "\n",
    "        # 차이 이미지에서 흰색 픽셀의 개수 계산\n",
    "        diff_cnt = cv2.countNonZero(diff)\n",
    "\n",
    "        # 차이가 있는 영역이 설정된 최대값보다 크면\n",
    "        if diff_cnt > max_diff:\n",
    "            # 차이가 있는 영역의 좌표 계산\n",
    "            nzero = np.nonzero(diff)\n",
    "            if len(nzero[0]) > 0 and len(nzero[1]) > 0:  # nzero가 비어있지 않은지 확인\n",
    "                # 차이 영역에 사각형 그리기\n",
    "                x1, y1, x2, y2 = min(nzero[1]), min(nzero[0]), max(nzero[1]), max(nzero[0])\n",
    "                cv2.rectangle(draw, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "\n",
    "                # 객체 검출을 위한 블롭 생성\n",
    "                blob = cv2.dnn.blobFromImage(c, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "                net.setInput(blob)\n",
    "                outs = net.forward(output_layers)\n",
    "\n",
    "                # 검출된 객체의 정보 저장\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.5:\n",
    "                            center_x = int(detection[0] * 720)\n",
    "                            center_y = int(detection[1] * 600)\n",
    "                            w = int(detection[2] * 720)\n",
    "                            h = int(detection[3] * 600)\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "                detected = False\n",
    "                for i in range(len(boxes)):\n",
    "                    if i in indexes:\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(classes[class_ids[i]])\n",
    "                        if label in [\"person\", \"cat\", \"dog\"]:  # 사람, 고양이, 개만 감지\n",
    "                            color = (0, 255, 0) if label == \"person\" else (0, 0, 255)\n",
    "                            # cv2.rectangle(draw, (x, y), (x + w, y + h), color, 2)\n",
    "                            cv2.putText(draw, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                            detected = True\n",
    "\n",
    "                if not detected:\n",
    "                    # 객체가 검출되지 않은 경우에도 모션 감지 영역에 텍스트 추가\n",
    "                    cv2.putText(draw, 'Motion Detection', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        # 현재 프레임과 차이 이미지를 나란히 붙여서 출력\n",
    "        stacked = np.hstack((draw, cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR)))\n",
    "        cv2.imshow('motion_sensor', stacked)\n",
    "\n",
    "        # 다음 프레임을 위해 변수 업데이트\n",
    "        a = b\n",
    "        b = c\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
